{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9b1c2a9",
   "metadata": {},
   "source": [
    "# Croping Faces Were Detecting "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c084a04",
   "metadata": {},
   "source": [
    "### Install necessary package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc9e8084",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mtcnn in c:\\users\\truong\\anaconda3\\lib\\site-packages (0.1.1)\n",
      "Requirement already satisfied: keras>=2.0.0 in c:\\users\\truong\\anaconda3\\lib\\site-packages (from mtcnn) (2.8.0)\n",
      "Requirement already satisfied: opencv-python>=4.1.0 in c:\\users\\truong\\anaconda3\\lib\\site-packages (from mtcnn) (4.5.3.56)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\truong\\anaconda3\\lib\\site-packages (from opencv-python>=4.1.0->mtcnn) (1.20.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install mtcnn\n",
    "# Note! Skiping step when having this available package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba94da2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mtcnn import MTCNN\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "import os\n",
    "\n",
    "def crop_image(image_path):\n",
    "    detector = MTCNN() \n",
    "    img=cv2.imread(image_path)\n",
    "\n",
    "    data = detector.detect_faces(img)\n",
    "    biggest=0\n",
    "    if data !=[]:\n",
    "        for faces in data:\n",
    "            box=faces['box']            \n",
    "            # calculate the area in the image\n",
    "            area = box[3]  * box[2]\n",
    "            if area>biggest:\n",
    "                biggest=area\n",
    "                bbox=box \n",
    "        bbox[0]= 0 if bbox[0]<0 else bbox[0]\n",
    "        bbox[1]= 0 if bbox[1]<0 else bbox[1]\n",
    "        img=img[bbox[1]: bbox[1]+bbox[3],bbox[0]: bbox[0]+ bbox[2]] \n",
    "        #img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) # convert from bgr to rgb\n",
    "        return (True, img) \n",
    "    else:\n",
    "        return (False, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6a53827",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Croping image:  data\\1.jpg\n",
      "Croping image:  data\\2.jpg\n",
      "WARNING:tensorflow:5 out of the last 17 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000013F834B6EE0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 18 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000013F834B6EE0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "Croping image:  data\\3.jpg\n",
      "Croping image:  data\\4.jpg\n",
      "Croping image:  data\\5.jpg\n"
     ]
    }
   ],
   "source": [
    "\n",
    "path = \"data\"\n",
    "result_path = \"img_crop\"\n",
    "list_path = os.listdir(path)\n",
    "list_imgs = []\n",
    "for i in list_path:\n",
    "  list_imgs.append(os.path.join(path,i))\n",
    "\n",
    "\n",
    "\n",
    "index = 0\n",
    "for i in list_imgs:\n",
    "  img_path = i\n",
    "  print(\"Croping image: \", i)\n",
    "  status, img=crop_image(img_path)\n",
    "  temp_path = os.path.join(result_path, str(index))\n",
    "  #print(temp_path)\n",
    "  if status:\n",
    "    cv2.imwrite(temp_path + '.jpg', img)\n",
    "    #print(temp_path + '.jpg')\n",
    "    index +=1\n",
    "    cv2.waitKey(0)\n",
    "  else:\n",
    "      print('No facial image was detected')\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
